### ۱. جدول نتایج نهایی

در این بخش، نتایج ارزیابی ۱۲ مدل Word2Vec بر اساس هایپرپارامترهای مختلف ارائه شده است.

| Arch | Win | Dim | WS353(%) | BATS_Inflec | BATS_Deriv | BATS_Encycl | BATS_Lexic |
|:---|---:|---:|---:|---:|---:|---:|---:|
| CBOW | 5 | 50 | 24.22 | 8.41 | 0.00 | 2.46 | 0.00 |
| CBOW | 10 | 50 | 26.78 | 8.41 | 0.00 | 2.46 | 0.00 |
| CBOW | 5 | 100 | 24.74 | 9.80 | 0.00 | 2.22 | 0.00 |
| CBOW | 10 | 100 | 30.25 | 7.92 | 0.00 | 1.97 | 0.00 |
| CBOW | 5 | 300 | 22.51 | 9.63 | 0.00 | 2.22 | 0.00 |
| CBOW | 10 | 300 | 28.32 | 8.65 | 0.00 | 1.23 | 0.00 |
| Skip-gram | 5 | 50 | 35.76 | 13.80 | 0.00 | 6.40 | 0.00 |
| Skip-gram | 10 | 50 | 39.89 | 17.31 | 0.00 | 5.91 | 0.00 |
| Skip-gram | 5 | 100 | 35.07 | 15.84 | 0.00 | 8.37 | 0.00 |
| Skip-gram | 10 | 100 | 41.22 | 17.31 | 0.00 | 8.13 | 0.00 |
| Skip-gram | 5 | 300 | 36.44 | 15.35 | 0.00 | 7.39 | 0.00 |
| Skip-gram | 10 | 300 | 41.01 | 14.53 | 0.00 | 6.40 | 0.00 |

---

### ۲. تحلیل و یافته‌های کلیدی

*   **معماری:** مدل‌های **Skip-gram** به طور واضح و در تمام تسک‌ها عملکرد بهتری نسبت به مدل‌های CBOW داشتند.
*   **تأثیر ابعاد:** ابعاد بزرگتر لزوماً بهتر نیستند. برای مثال، مدل Skip-gram با ابعاد ۱۰۰ (امتیاز ۴۱.۲۲٪) از مدل با ابعاد ۳۰۰ (امتیاز ۴۱.۰۱٪) در تسک WordSim353 بهتر عمل کرد.
*   **شکست در تسک‌های BATS:** یک یافته مهم، امتیاز **صفر** تمامی مدل‌ها در تسک‌های `Derivational` و `Lexicographic` بود. این موضوع نشان‌دهنده **ناتوانی مدل در یادگیری روابط پیچیده معنایی** از مجموعه داده محدود WikiText-2 است.
*   **تحلیل کیفی:**
    *   **بهترین مدل** (`Skip-gram, Win=10, Dim=100`) همسایه‌های کاملاً مرتبط (مانند `star` -> `actor`, `planet`) تولید کرد.
    *   **بدترین مدل** (`CBOW, Win=5, Dim=300`) همسایه‌های بی‌ربط و ایست‌واژه (مانند `bank` -> `the`, `and`) برگرداند.
    *   **اندازه پنجره:** پنجره کوچکتر (Win=5) همسایه‌های **نحوی** (syntactic) مانند `run` -> `running` و پنجره بزرگتر (Win=10) همسایه‌های **معنایی** (semantic) مانند `run` -> `marathon` را ترجیح داد.

---

### ۳. نتیجه‌گیری

نتایج تأیید می‌کنند که **Skip-gram** معماری بهتری برای این تسک است. هایپرپارامترها نقش مهمی در عملکرد دارند اما باید متناسب با داده انتخاب شوند. **محدودیت اصلی عملکرد، اندازه کوچک مجموعه داده آموزشی بود** که مانع از یادگیری روابط پیچیده کلمات شد.